{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_17_machine_learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwIziAXheU_m"
      },
      "source": [
        "1. Using a graph to illustrate slope and intercept, define basic linear regression.\n",
        "Ans: \n",
        "\n",
        "\n",
        "2. In a graph, explain the terms rise, run, and slope.\n",
        "Ans: \n",
        "A slope of 1 on a graph goes through points (1,1), (2,2), (3,3), … (n,n), (-1,-1),(-2,-2),(-3,-3),…(-n,-n). To determine the slope from a graph, see how many points/grids it takes to go straight up (rise) and then straight across (run) to again be on the line. The rise must equal the run\n",
        " (for a slope of 1), and both points must be either positive/positive or negative/negative to have a slope of positive 1.\n",
        "3. Use a graph to demonstrate slope, linear positive slope, and linear negative slope, as well as the different conditions that contribute to the slope.\n",
        "\n",
        "\n",
        "4. Use a graph to demonstrate curve linear negative slope and curve linear positive slope.\n",
        "Ans: \n",
        "\n",
        "\n",
        "5. Use a graph to show the maximum and low points of curves.\n",
        "\n",
        "6. Use the formulas for a and b to explain ordinary least squares.\n",
        "\n",
        "7. Provide a step-by-step explanation of the OLS algorithm.\n",
        "Ans: \n",
        "OLS chooses the parameters of a linear function of a set of explanatory variables by the principle of least squares: minimizing the sum of the squares of the differences between the observed dependent variable \n",
        "(values of the variable being observed) in the given dataset and those predicted by the linear function of the independent variable.\n",
        "\n",
        "8. What is the regression's standard error? To represent the same, make a graph.\n",
        "ANs: \n",
        "In statistics, the reduced chi-square statistic is used extensively in goodness of fit testing. It is also known as \n",
        "mean squared weighted deviation in isotopic dating and variance of unit weight in the context of weighted least squares\n",
        "\n",
        "9. Provide an example of multiple linear regression.\n",
        "Ans: \n",
        "As an example, an analyst may want to know how the movement of the market affects the price of ExxonMobil (XOM). In this case, their linear equation will have the \n",
        "value of the S&P 500 index as the independent variable, or predictor, and the price of XOM as the dependent variable.\n",
        "\n",
        "10. Describe the regression analysis assumptions and the BLUE principle.\n",
        "Ans: \n",
        "The term “linear regression” is not well defined and does not specify a unique objective function. Admittedly, I typically let this issue slide a bit; when folks colloquially say “linear regression”, I assume they are referring to OLS Linear Regression. However, in the interest of being well specified in our language, we should explicitly refer to OLS by name.\n",
        "The question “what assumptions are required for OLS Linear Regression” is still an ill-posed and unanswerable question. Why? Because we have not explicitly specified what we want to use the OLS Linear Regression for, nor what requirements we need from it? For example:\n",
        "\n",
        "11. Describe two major issues with regression analysis.\n",
        "Ans: \n",
        "there is some or much non-linear (curvilinear) dependence. This can easily be overlooked when the curvilinearity isn’t extreme, \n",
        "and that particularly can lead to really bad predictions when extrapolating outside the range of data in the analysis.\n",
        "\n",
        "12. How can the linear regression model's accuracy be improved?\n",
        "Ans: \n",
        "Having more data is always a good idea. It allows the “data to tell for itself,” instead of relying on assumptions and weak correlations. Presence of more data results in better and accurate models.\n",
        "\n",
        "13. Using an example, describe the polynomial regression model in detail.\n",
        "Ans: \n",
        "Matrix Multiplication\n",
        "\n",
        "Consider a set of n+1 data points {(x0, y0), (x1, y1)... }which you want to regress to a polynomial of degree n. Let matrix A be the matrix:\n",
        "1 x0 x0^2 ... x0^n\n",
        "1 x1 x1^2 ... x1^n\n",
        "...\n",
        "1 x(n+1) x(n+1)^2 ... x(n+1)^n\n",
        "\n",
        "Let matrix B be the column vector of the Y values.\n",
        "\n",
        "You wish to solve for the column vector of coefficients of your polynomial, call this vector x.\n",
        "\n",
        "Noting that Ax=B, solving for x, we perform polynomial regression on the set.\n",
        "\n",
        "14. Provide a detailed explanation of logistic regression.\n",
        "Ans: \n",
        "Logistic regression is a statistical analysis method used to predict a data value based on prior observations of a data set.\n",
        "Based on historical data about earlier outcomes involving the same input criteria, it then scores new cases on their probability of falling into a particular outcome category.\n",
        "\n",
        "15. What are the logistic regression assumptions?\n",
        "Ans: The logistic regression method assumes that: The outcome is a binary or dichotomous variable like yes vs no, positive vs negative, 1 vs 0. There is a linear relationship between the logit of the outcome and each predictor variables\n",
        "\n",
        "\n",
        "16. Go through the details of maximum likelihood estimation.\n",
        "Ans: \n",
        "In statistics, maximum likelihood estimation (MLE) is a method of estimating the parameters of an assumed probability distribution, given some observed data.\n",
        " This is achieved by maximizing a likelihood function so that, under the assumed statistical model, the observed data is most probable.\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}