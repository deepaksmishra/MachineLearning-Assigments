{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignemnet_15.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VurlksIeUkK5"
      },
      "source": [
        "1. Recognize the differences between supervised, semi-supervised, and unsupervised learning.\n",
        "Ans: \n",
        "Semi-supervised learning aims to label unlabeled data points using knowledge learned from a small number of labeled data points. Unsupervised learning does \n",
        "not have (or need) any labeled outputs, so its goal is to infer the natural structure present within a set of data points\n",
        "\n",
        "\n",
        "2. Describe in detail any five examples of classification problems.\n",
        "Ans: \n",
        "Customer behavior prediction: Customers can be classified into different categories based on their buying patterns, web store browsing patterns etc. For example, classification models can be used to determine whether a customer is likely to purchase more items or not. If the classification model predicts a greater likelihood that they are about to make more purchases, then you might want to send them promotional offers and discounts accordingly. Or if it has been determined that they will probably fall off of their purchasing habits soon, maybe save them for later by making their information readily available.\n",
        "Document classification: A multinomial classification model can be trained to classify documents in different categories.\n",
        "Image classification: A multinomial classification model can be trained to classify images into different categories. For example, in order to classify images of dogs and cats for use within machine vision systems, machine learning techniques can help automate this process based on pre-classified images of dogs and cats.rent categories\n",
        "Web text classification: Classifies web text or assign tag to web text based on pre-determined categories learned from the past data. For example, classification models can be used to automatically classify web text into one of the following categories: Sports, Entertainment, or Technology.\n",
        "Ad click-through rate prediction: Binary classification models can be used to predict whether one or more ads on the website will be clicked or not. Such models are used to optimize the ad inventory on websites by selecting which ads will have a better chance of being clicked. A machine learning classification model can be built using historical data about what types of users do or don’t click on certain ads, along with information like demographics and content within each web page where an ad appears; then it is used to predict the chances that a user will click on an ad.\n",
        "Product categorization: A multinomial classification can be used to categorize the products sold by different retailers in the same categories irrespective of categories assigned to the product by the respective retailers. This use case is relevant for eCommerce aggregators. Read this page on product categorization for greater details.\n",
        "Malware classification: A multinomial classification can be used to classify the new/emerging malwares on the basis of comparable features of similar malware. Malware classification is very useful for security experts to take appropriate actions for combating/preventing malware. Machine learning classification algorithms such as Naïve Bayes, k-NN and tree-based models can be used for malware classification.\n",
        "Image sentiment analysis: Machine learning binary classification models can be built based on machine learning algorithms to classify whether the image contains a positive or negative emotion/sentiment or not. This use case is relevant in the field of social media analytics where machine learning techniques are applied to understand users’ opinions and sentiments on different topics.\n",
        "Customer churn prediction: A binary classification model can be used to classify whether a customer will churn or not in the near future. The application of the customer churn classification model can be found in different business scenarios like up-selling/cross-selling to existing customers, identifying at-risk accounts in the customer base, etc. More commonly, telecommunications companies have been found to use machine learning classification models for churn prediction.\n",
        "Customer behavior assessment for promotional offers: A binary classification model can be used to classify whether an account is customer-friendly or not in the context of a specific business scenario like upselling, cross-selling etc. For example, based on past data about how customers respond to certain types of offers; machine learning techniques can be used to predict whether a given customer will respond positively or negatively to the offer.\n",
        "Anomaly detection problems such as fraud detection: Anomaly detection models can be built using machine learning classification algorithms like Naïve Bayes, k-NN etc. The application of these machine learning anomaly detection models is very wide and includes use cases such as finding unusual patterns in financial transactions that may indicate fraud, finding machine problems by detecting unusual machine readings, and monitoring machine parameters to detect abnormalities.\n",
        "Credit card fraud detection: A binary classification model can be used for credit card fraud detection where the historical transactions data of a customer is analyzed using machine learning algorithms like Naïve Bayes, k-NN etc. Based on past fraudulent or non-fraudulent transaction data and machine learning classification models, it can be predicted whether the given credit card will result in fraudulent transactions or not.\n",
        "\n",
        "3. Describe each phase of the classification process in detail.\n",
        "Ans: \n",
        "\n",
        "4. Go through the SVM model in depth using various scenarios.\n",
        "Ans: \n",
        "Support vector machines are a set of supervised learning methods used for classification, regression, \n",
        "and outliers detection. All of these are common tasks in machine learning.\n",
        "There are specific types of SVMs you can use for particular machine learning problems, \n",
        "like support vector regression (SVR) which is an extension of support vector classification (SVC).\n",
        "\n",
        "5. What are some of the benefits and drawbacks of SVM?\n",
        "Ans: \n",
        "SVM algorithm is not suitable for large data sets.\n",
        "SVM does not perform very well when the data set has more noise i.e. target classes are overlapping.\n",
        "In cases where the number of features for each data point exceeds the number of training data samples, the SVM will underperform.\n",
        "As the support vector classifier works by putting data points, above and below the classifying hyperplane there is no probabilistic explanation for the classification.\n",
        "\n",
        "6. Go over the kNN model in depth.\n",
        "Ans: \n",
        "kNN is the simplest machine learning algorithm to understand and also to explain.\n",
        "It is a versatile algorithm i.e. useful for both classification and regression.\n",
        "It has one big advantage is that kNN ha no pre assumption about the data. “ Let the data speak for itself ”.\n",
        "\n",
        "\n",
        "7. Discuss the kNN algorithm's error rate and validation error.\n",
        "Ans: \n",
        "KNN falls in the supervised learning family of algorithms. Informally, this means that we are given a labelled dataset consiting of training observations (x,y) and would like to capture the relationship between x and y. More formally, \n",
        "our goal is to learn a function h:X→Y so that given an unseen observation x, h(x) can confidently predict the corresponding output y.\n",
        "\n",
        "8. For kNN, talk about how to measure the difference between the test and training results.\n",
        "Ans: \n",
        "The training data is the data we use to fit a model.  The test data is the data we use to evaluate a model. \n",
        "For KNN the train data is the data that get's used to vote on the class label of a new data point (KNN doesn't really involve any training).\n",
        "\n",
        "9. Create the kNN algorithm.\n",
        "Ans: \n",
        "\n",
        "10.What is a decision tree, exactly? What are the various kinds of nodes? Explain all in depth.\n",
        "Ans: There are three different types of nodes: chance nodes, decision nodes, and end nodes. A chance node, represented by a circle, shows the probabilities of certain results.\n",
        " A decision node, represented by a square, shows a decision to be made, and an end node shows the final outcome of a decision path.\n",
        "\n",
        "11. Describe the different ways to scan a decision tree.\n",
        "Ans: \n",
        "The “Decision Tree Algorithm” may sound daunting, but it is simply the math that determines how the tree is built (“simply”…we’ll get into it!). The algorithm currently implemented in sklearn is called “CART” (Classification and Regression Trees), which works for only numerical features, but works with both numerical and categorical targets (regression and classification). At each node, it determines the feature and split threshold of that feature which will yield the\n",
        " “largest information gain” for the model. This “information gain” is measured based on the splitting criteria specified by the user.\n",
        "\n",
        "12. Describe in depth the decision tree algorithm.\n",
        "Ans: \n",
        "Decision Tree algorithm belongs to the family of supervised learning algorithms. The goal of using a Decision Tree is to create a training model that can use to predict the class or value of the target variable by learning simple decision rules inferred from prior data(training data). ...\n",
        "\n",
        "13. In a decision tree, what is inductive bias? What would you do to stop overfitting?\n",
        "Ans: \n",
        "Over-fitting is the phenomenon in which the learning system tightly fits the given training data so much that it would be inaccurate in predicting the outcomes of the untrained data.\n",
        "In decision trees, over-fitting occurs when the tree is designed so as to perfectly fit all samples in the training data set. Thus it ends up with branches with strict rules of sparse data. Thus this effects the accuracy when predicting samples that are not part of the training set.\n",
        "One of the methods used to address over-fitting in decision tree is called pruning which is done after the initial training is complete. In pruning, you trim off the branches of the tree, i.e., remove the decision nodes starting from the leaf node such that the overall accuracy is not disturbed. This is done by segregating the actual training set into two sets: training data set, D and validation data set, V. Prepare the decision tree using the segregated training data set, D. Then continue trimming the tree accordingly to optimize the accuracy of the validation data set, V.\n",
        "Details of decision tree over-fitting and pruning is given in the book Machine Learning by Tom Mitchell. It should be simple for beginners to understand.\n",
        "\n",
        "14.Explain advantages and disadvantages of using a decision tree?\n",
        "Ans: \n",
        "Advantages and Disadvantages of Decision Trees in Machine Learning. Decision Tree is used to solve both classification and regression problems.\n",
        " But the main drawback of Decision Tree is that it generally leads to overfitting of the data.\n",
        "\n",
        "15. Describe in depth the problems that are suitable for decision tree learning.\n",
        "Ans: \n",
        "verfitting the data: \n",
        "Guarding against bad attribute choices: \n",
        "Handling continuous valued attributes: \n",
        "Handling missing attribute values: \n",
        "Handling attributes with differing costs:\n",
        "\n",
        "16. Describe in depth the random forest model. What distinguishes a random forest?\n",
        "Ans: \n",
        "Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time. \n",
        " Random forests generally outperform decision trees, but their accuracy is lower than gradient boosted trees.\n",
        "\n",
        "17. In a random forest, talk about OOB error and variable value.\n",
        "Ans: \n",
        "Out-of-bag (OOB) error, also called out-of-bag estimate, is a method of measuring the prediction error of random forests, boosted decision trees, and other machine learning models utilizing bootstrap aggregating (bagging). \n",
        "Bagging uses subsampling with replacement to create training samples for the model to learn from.\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}