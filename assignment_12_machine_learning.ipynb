{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_12_machine learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdFtTFalB7r5"
      },
      "source": [
        "1. What is prior probability? Give an example.\n",
        "Ans: \n",
        "Prior probability shows the likelihood of an outcome in a given dataset. For example, in the mortgage case, P(Y) is the default rate on a home mortgage, which is 2%. P(Y|X) is called the conditional probability, \n",
        "which provides the probability of an outcome given the evidence, that is, when the value of X is known.\n",
        "\n",
        "2. What is posterior probability? Give an example.\n",
        "Ans: \n",
        "Posterior probability is a revised probability that takes into account new available information. For example, let there be two urns, urn A having 5 black balls and 10 red balls and urn\n",
        " B having 10 black balls and 5 red balls. Now if an urn is selected at random, the probability that urn A is chosen is 0.5.\n",
        "\n",
        "Suppose you have a probability model with parameters θ.\n",
        "p(x | θ) has two names.\n",
        "It can be called the probability of x (given θ),\n",
        "or the likelihood of θ (given that x was observed).\n",
        "\n",
        "The likelihood is a function of θ. Here are a couple of simple uses:\n",
        "\n",
        "If you observe x and want to estimate the θ that gave rise to it, the maximum-likelihood principle says to choose the maximum-likelihood θ -- in other words, the θ that maximizes p(x | θ).\n",
        "\n",
        "This contrasts with the maximum-a-posteriori or MAP estimate, which is the θ that maximizes p(θ | x). Since x is fixed, this is equivalent to maximizing p(θ) p(x | θ), the product of the prior probability of θ with the likelihood of θ.\n",
        "\n",
        "You can do more with these functions of θ than just maximize them. Much is known about their typical shape as the size of the dataset x increases.\n",
        "\n",
        "4. What is Naïve Bayes classifier? Why is it named so?\n",
        "Ans:\n",
        "A naive Bayes classifier assumes that the presence (or absence) of a particular feature of a class is unrelated to the presence (or absence) of any other feature, given the class variable.\n",
        " Basically, it's \"naive\" because it makes assumptions that may or may not turn out to be correct.\n",
        "\n",
        "\n",
        "5. What is optimal Bayes classifier?\n",
        "Ans: \n",
        "The Bayes Optimal Classifier is a probabilistic model that makes the most probable prediction for a new example. Bayes Optimal Classifier is a probabilistic model \n",
        "that finds the most probable prediction using the training data and space of hypotheses to make a prediction for a new data instance.\n",
        "\n",
        "\n",
        "6. Write any two features of Bayesian learning methods.\n",
        "Ans: \n",
        "Bayesian machine learning allows us to encode our prior beliefs about what those models should look like,\n",
        "independent of what the data tells us. This is especially useful when we don’t have a ton of data to confidently learn our model.\n",
        "\n",
        "\n",
        "7. Define the concept of consistent learners.\n",
        "Ans: \n",
        "Consistent Learners. • A learner L using a hypothesis H and training data D is said to be a consistent learner if it always outputs a hypothesis with zero error on D whenever H contains such a hypothesis.\n",
        "a consistent learner must produce a hypothesis in the version space for H given D.\n",
        "\n",
        "8. Write any two strengths of Bayes classifier.\n",
        "Ans: \n",
        "This algorithm works quickly and can save a lot of time. Naive Bayes is suitable for solving multi-class prediction problems. \n",
        "If its assumption of the independence of features holds true, it can perform better than other models and requires much less training data.\n",
        "\n",
        "9. Write any two weaknesses of Bayes classifier.\n",
        "Ans: \n",
        "1. Main imitation of Naive Bayes is the assumption of independent predictors. Naive Bayes implicitly assumes that all the attributes are mutually independent. In real life, it is almost impossible that we get a set of predictors which are completely independent.\n",
        "\n",
        "2. If categorical variable has a category in test data set, which was not observed in training data set, then model will assign a 0 (zero) probability and will be unable to make a prediction. This is often known as Zero Frequency.\n",
        "\n",
        "\n",
        "10. Explain how Naïve Bayes classifier is used for\n",
        "\n",
        "        1. Text classification\n",
        "ANs: Text classification is a machine learning technique that assigns a set of predefined categories to open-ended text. Text classifiers can be used to organize,\n",
        " structure, and categorize pretty much any kind of text – from documents, medical studies and files, and all over the web.\n",
        "\n",
        "        2. Spam filtering\n",
        "Ans: A spam filter is a program that is used to detect unsolicited and unwanted email and prevent those messages from getting to a user's inbox. ... This method is not especially effective, \n",
        "too often omitting perfectly legitimate messages (these are called false positives) and letting actual spam through.\n",
        "\n",
        "       3. Market sentiment analysis\n",
        "Ans: Sentiment analysis is the use of natural language processing (NLP), machine learning, and other data analysis techniques to analyze and derive objective quantitative results from raw text.\n",
        "\n",
        "Learn more about how sentiment analysis works, its challenges, and how you can use sentiment analysis to improve processes, decision-making, customer satisfaction and more.\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}